---
title: Pyrovelocity PyPI user notebook template
toc: true
number-sections: true
highlight-style: pygments
csl: bibstyle.csl
lightbox: auto
format:
  nature-pdf:
    natbibstyle: sn-nature
    # classoption:
    #   - lineno
    cite-method: citeproc
    keep-tex: true
  html:
    mainfont: Latin Modern Sans
    code-fold: false
    html-math-method: katex
    embed-resources: true
  docx: default
  ipynb: default
format-links: false
execute: 
  eval: true
  warning: false
  error: false
  cache: true
  keep-ipynb: true
  keep-md: true
author:
  - name: Pyrovelocity Team
    email: team@pyrovelocity.net
abstract: |
  This notebook demonstrates how to run pyrovelocity in a Jupyter notebook.
  It attempts to support both Google Colab and local or remote Jupyter kernel servers.
keywords: [single-cell transcriptomics, probabilistic modeling, dynamical systems, RNA velocity]
bibliography: references.bib
jupyter:
  jupytext:
    cell_metadata_filter: all
    cell_metadata_json: true
    notebook_metadata_filter: all
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: 1.0
      jupytext_version: 1.16.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
  language_info:
    name: python
  rise:
    scroll: true
    theme: black
  toc-autonumbering: true
  toc-showcode: false
  toc-showmarkdowntxt: false
---

<a target="_blank" href="https://colab.research.google.com/github/pinellolab/pyrovelocity/blob/530-nbwf/docs/source/notebooks/pyrovelocity_pypi_user_template.ipynb">
  <img 
    src="https://colab.research.google.com/assets/colab-badge.svg" 
    alt="Open In Colab"
    width="109" height="20"/>
</a> <a target="_blank" href="https://nbviewer.jupyter.org/github/pinellolab/pyrovelocity/blob/530-nbwf/docs/source/notebooks/pyrovelocity_pypi_user_template.ipynb">
  <img 
    src="https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.png"
    alt="Render with nbviewer" 
    width="109" height="20"/>
</a>

```{python}
#| label: blank-cell-01
print("This cell is intentionally left blank.") 
``` 

## Setup environment

```{python}
#| label: blank-cell-02
print("This cell is intentionally left blank.") 
``` 

### Overview

Installation should take less than **5 minutes**. 
It involves checking if the notebook is running in colab, in which case it is certain that you will need to install or reinstall pyrovelocity.
Otherwise, it is assumed that the user will have installed pyrovelocity in the same environment in which the jupyter kernel is running.

The simplest way to complete it is to run the `Setup environment` section, wait for the kernel to restart, and then run the same section again:

- **fold** this `Setup environment` section above
- **click the play button** underneath the section name to run the whole section for the first time
- **wait** for the kernel to restart 
  - **ignore** expected notice in bottom left of Colab UI
    - `Your session crashed for an unknown reason. View runtime logs`
  - **ignore** `SystemExit` output in the `Install pyrovelocity` subsection below
- **refold** the `Setup environment` section (`SystemExit` / kernel restart will unfold it)
- **proceed to Analysis** below

Otherwise, the cells below can be executed manually.
In either case, this section can be folded away after installation is complete.

If you need to edit the **version number**, please see the setting in the `setup_pyrovelocity` function below.

### Install library

This first stage will download and install [pyrovelocity](https://github.com/pinellolab/pyrovelocity). This usually takes less than **4 minutes**. The runtime will then automatically restart. After this you can execute "Run all" to complete installation or proceed linearly below if you have added additional content you do not want to run all at once.

#### Define functions to manage installation of python libraries

```{python}
#| label: install-package-helpers
#| code-fold: true
import importlib.util
import subprocess
import sys


def is_module_available(module_name: str):
    return importlib.util.find_spec(module_name) is not None


def install_package(package_name: str):
    """
    Install a package using pip. This is similar to cell magic
    `!pip install package_name`, but in python code for compatibility
    outside jupyter.

    Args:
        package_name (str): Name of the package to install.
    """
    process = subprocess.Popen(
        ["pip", "install", "-q", package_name],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
    )
    for line in process.stdout:
        print(line, end="")
    for line in process.stderr:
        print(line, end="")
    process.wait()

def setup_pyrovelocity():
    if is_module_available("pyrovelocity"):
        try:
            import pyrovelocity
        except (ImportError, AssertionError):
            print("pyrovelocity is not successfully installed")
            sys.exit()
    else:
        print("Installing pyrovelocity...")
        install_package("pyrovelocity[workflows] @ git+https://github.com/pinellolab/pyrovelocity.git@530-nbwf")
        try:
            import pyrovelocity

            print(
                "\nThe kernel needs to restart in order to use pyrovelocity.\n"
                "Please run this cell again.\n"
            )
            sys.exit()
        except (ImportError, AssertionError):
            print("Failed to install pyrovelocity properly.")
            sys.exit()
```

#### Install pyrovelocity

```{python}
#| label: install-pyrovelocity-colab
#| code-fold: true
import os

IN_COLAB = is_module_available("google.colab")

if IN_COLAB:
    colab_release_tag = os.getenv("COLAB_RELEASE_TAG", None)
    print(f"Google Colab release: {colab_release_tag}")
    setup_pyrovelocity()
else:
    print("This notebook is probably not running in Google Colab")
```

### Check installation

If installation was successful, the following commands should print the location of the `__init__.py` file for the pyrovelocity package and the currently installed version.

```{python}
#| label: check-pyrovelocity-installation
#| output: false

import pyrovelocity
if IN_COLAB:
  print(pyrovelocity.__file__)
print(pyrovelocity.__version__)
```

This is the same for the pyro package in case there was an issue with pyrovelocity install that did not affect another package.

```{python}
#| label: check-pyro-installation
#| code-fold: true
#| output: false

import pyro
if IN_COLAB:
  print(pyro.__file__)
print(pyro.__version__)
```

Please refer to the [docs](https://pinellolab.github.io/pyrovelocity) for tutorials and usage information.

## Analysis

```{python}
#| label: print-pyrovelocity-docstring-1
pyrovelocity.help.internal_help(pyrovelocity) # ?pyrovelocity # to open in side panel tab for reference
```

Before we start, we will adjust a few environment variables to ensure our first execution occurs in a lightweight test mode with a subset of observations, variables, training epochs, and posterior samples. We will also set a few log levels. Feel free to adjust these to `ERROR`, `DEBUG`, etc as needed.

```{python}
#| label: set-pyrovelocity-testing-flag
import os
os.environ["PYROVELOCITY_TESTING_FLAG"] = "True"
os.environ["PYROVELOCITY_LOG_LEVEL"] = "INFO" 

import logging
logging.getLogger("jax").setLevel(logging.ERROR)
logging.getLogger("root").setLevel(logging.ERROR)
```

After an initial review, we can set the environment variable to `False` to run the full analysis.

The library supports execution via a sequence of workflow tasks. The approximate outline of these involves accessing external data, preprocessing, model training, postprocessing, and summarization.

We import these tasks and execute them in the subsections below.

```{python}
#| label: import-notebook-dependencies
from importlib import reload

import yaml
from IPython.display import Image
# from IPython.display import display

import pyrovelocity.utils
import pyrovelocity.workflows.main_workflow
reload(pyrovelocity.utils)
reload(pyrovelocity.workflows.main_workflow)

from pyrovelocity.utils import print_config_tree
from pyrovelocity.utils import print_docstring
from pyrovelocity.workflows.main_workflow import download_data
from pyrovelocity.workflows.main_workflow import postprocess_data
from pyrovelocity.workflows.main_workflow import preprocess_data
from pyrovelocity.workflows.main_workflow import summarize_data
from pyrovelocity.workflows.main_workflow import train_model
```

To execute each task requires a single `WorkflowConfiguration` object, which is an instance of a python datclass. In this notebook we illustrate execution with the standard pancreatic endocrinogenesis data set [@Bastidas-Ponce2019-lf]. First we import the configuration dataclass

```{python}
#| label: import-pancreas-configuration
from pyrovelocity.workflows.main_configuration import pancreas_configuration
```

We can review the configuration dataclass by writing it to a yaml file or printing the dictionary representation to the console.

```{python}
#| label: print-and-save-pancreas-configuration
pancreas_configuration_dict = pancreas_configuration.to_dict()
print_config_tree(pancreas_configuration_dict, "pancreas configuration")

with open("pancreas_configuration.yaml", "w") as yaml_file:
    yaml.dump(pancreas_configuration_dict, yaml_file, sort_keys=False, default_flow_style=False, allow_unicode=True)
```

Feel free to open the [pancreas_configuration.yaml](./pancreas_configuration.yaml) file to review the configuration settings. We will reprint the part of that configuration relevant to the execution of each task below. The resource requests and limits sections at the bottom will be irrelevant for this example of local execution. The resource specifications are utilized during local or remote cluster-based execution of distributed containerized workflows.

### Download data

To download data, we provide the `download_data` task function with the `download_dataset` attribute of the `pancreas_configuration` object.

```{python}
#| label: print-download-dataset-configuration
print_config_tree(pancreas_configuration.download_dataset.to_dict(), "download dataset")
```

This configuration primarily specifies the location to store the data and the data set name that is mapped to a source URL in the `pyrovelocity.utils.datasets` module. The other parameters can be used to specify a custom source URL or to filter the observations and variables to a subset of the full data set; however, since we are working with a natively supported data set we do not need to specify those here.

::: {.callout-note collapse=true title="Local caching"}
During local execution, all of the functions imported from the `pyrovelocity.workflows.main_workflow` module will cache their results. This means that if you run the same task function with the same arguments, it will not recompute the result, but just establish the presence of a cache hit. This is useful for avoiding redundant computation, but if you want to re-execute the function for testing, experimentation or other purposes. To avoid this, you can use the `pyrovelocity.utils.clear_local_cache` function to clear the cache. If you add the following block of code, the cache will be cleared whenever it is executed:

```python
from pyrovelocity.utils import clear_local_cache

clear_local_cache()
```

You can also disable the cache setting the `PYROVELOCITY_CACHE_FLAG` environment variable to `False`. For example, you can add the following block of code to the notebook to disable the cache for all task functions:

```python
import os
os.environ["PYROVELOCITY_CACHE_FLAG"] = "False"
```

For reference, during local execution, the cache is managed with a sqlite database by the [diskcache](https://grantjenks.com/docs/diskcache/) library via [flytekit](https://docs.flyte.org/).
:::

```{python}
#| label: execute-download-data-task
data = download_data(download_dataset_args=pancreas_configuration.download_dataset)
```


### Preprocess data

The preprocess data task is executed with the `preprocess_data` function. The `preprocess_data` function takes the `FlyteFile` object, here named `data` above, from `download_data` task function and the `preprocess_data` attribute of the `pancreas_configuration` object as arguments.

```{python}
#| label: print-preprocess-data-configuration
print_config_tree(pancreas_configuration.preprocess_data.to_dict(), "preprocess data")
```

The components of the preprocess data configuration are determined by the components of the `pyrovelocity.preprocess.preprocess_dataset` function whose documentation can be accessed via `help` or `?` in the notebook

```{python}
#| label: print-preprocess-data-docstring
print_docstring(pyrovelocity.preprocess.preprocess_dataset)
```

Recall that the output of the `preprocess_data` function below will be cached and should rerun almost instantaneously if you re-execute the cell multiple times.

```{python}
#| label: execute-preprocess-data-task
processed_data = preprocess_data(
  data=data,
  preprocess_data_args=pancreas_configuration.preprocess_data,
)
```

### Train model

The train model task is executed with the `train_model` function. The `train_model` task function takes the `FlyteFile` object, here named `processed_data` above, from `preprocess_data` task function and one of the `PyrovelocityTrainInterface` objects such as is found in the `training_configuration_2` attribute of the `pancreas_configuration` object as arguments.

The configuration is given by

```{python}
#| label: print-train-model-configuration
print_config_tree(pancreas_configuration.training_configuration_2.to_dict(), "train model 2")
```

The `PyrovelocityTrainInterface` is a configuration for the `pyrovelocity.train.train_dataset` function whose documentation we print below.

```{python}
#| label: print-train-model-docstring
print_docstring(pyrovelocity.train.train_dataset)
```

Finally, we execute the `train_model` task function 

```{python}
#| label: execute-train-model-task
model_output = train_model(
  processed_data=processed_data,
  train_model_configuration=pancreas_configuration.training_configuration_2,
)
```

This produces the `model_output` object, which is an instance of the `TrainingOutputs` dataclass.

```{python}
#| label: print-model-output
print_config_tree(model_output.to_dict(), "model output")
```

Due to caching, the paths to the model outputs will involve temporary folders, but the relevant outputs are also available in the `models` folder next to the notebook.

### Postprocess data

The postprocess data task is executed with the `postprocess_data` function. The `postprocess_data` function takes the preprocess data configuration, the training outputs, here named `model_output` above, from the `train_model` task function and the `postprocess_configuration` attribute of the `pancreas_configuration` object as arguments.

```{python}
#| label: print-postprocess-data-configuration
print_config_tree(pancreas_configuration.postprocess_configuration.to_dict(), "postprocess data")
```

The configuration required to postprocess the data are determined by the components of the `pyrovelocity.postprocess.postprocess_dataset` function interface whose documentation can be accessed via `help` or `?` in the notebook

```{python}
#| label: print-postprocess-data-docstring
print_docstring(pyrovelocity.postprocess.postprocess_dataset)
```

We execute the `postprocess_data` task function with the inputs described above.

```{python}
#| label: execute-postprocess-data-task
#| output: false 
from pyrovelocity.utils import SuppressOutput 

with SuppressOutput():
  postprocessing_outputs = postprocess_data(
    preprocess_data_args=pancreas_configuration.preprocess_data,
    training_outputs=model_output,
    postprocess_configuration=pancreas_configuration.postprocess_configuration,
  )
```

## Results

Now we have what is required to construct a summary of the results. The `summarize_data` task function takes the preprocessing configuration, `postprocessing_outputs` object and the `model_outputs` and generates a suite of plots summarizing the results.

```{python}
#| label: execute-summarize-data-task
#| output: false
dataset_summary = summarize_data(
  preprocess_data_args=pancreas_configuration.preprocess_data,
  postprocessing_outputs=postprocessing_outputs,
  training_outputs=model_output,
)
```

The dataset summary contains

```{python}
#| label: print-dataset-summary
print_config_tree(dataset_summary.to_dict(), "dataset summary")
```


### Data set review 
```{python}
#| label: import-ipython-display
#| echo: true
from IPython.display import Image, display
```

The maximum values of the unspliced and spliced count data for each gene across cells is shown in @fig-raw-counts.

```{python}
#| label: fig-raw-counts
#| echo: true
#| fig-cap: "Maximum spliced and unsliced transcript counts data for each gene across all cells with marginal histograms."
 
display(Image(filename=f"data/processed/pancreas_thresh_histogram.pdf.png"))
```


### Cell state transformation vector field estimates

A vector field estimate of cell state transformation probability derived from RNA velocity estimates with cluster annotations is shown in @fig-vector-field. 

```{python}
#| label: fig-vector-field
#| echo: true
#| fig-cap: "Vector field" 
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/vector_field.pdf.png"))
```

#### Vector field uncertainty estimates

@fig-vector-fields-uncertainty shows a low-dimensional representation of the RNA velocity vector fields with uncertainty estimates for shared time and angle. The latter quantity is estimated in PCA space. The base magnitude uncertainty is also shown but may not be interpretable.

```{python}
#| label: fig-vector-fields-uncertainty
#| echo: true
#| fig-cap: "Vector fields with uncertainty estimates."
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/fig2_part1_plot.pdf.png"))
```

### Gene selection

A *volcano plot* adapted for probabilistic inference of RNA velocity is shown in @fig-volcano. This plot shows the mean absolute error versus shared time correlation for each gene.

```{python}
#| label: fig-volcano
#| echo: true
#| fig-cap: "RNA velocity volcano plot showing mean absolute error versus shared time correlation for each gene."
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/volcano.pdf.png"))
```

#### Splice state phase portraits

@fig-rainbow shows the splice state phase portraits, estimated expression levels over shared time, and shared time correlation for a subset of selected genes.

```{python}
#| label: fig-rainbow
#| echo: true
#| fig-cap: "Splice state phase portraits, estimated expression levels over shared time, and shared time correlation for a subset of selected genes."
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/rainbow.pdf.png"))
```

#### Summary

A summary of the gene selection results is shown in @fig-gene-selection-summary.

```{python}
#| label: fig-gene-selection-summary
#| echo: true
#| fig-cap: "Summary of gene selection results."
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/fig2_part2_plot.pdf.png"))
```

### Uncertainty estimation

#### Parameter estimates

Estimates for parameter uncertainties for a subset of genes are shown in @fig-parameter-uncertainty.


```{python}
#| label: fig-parameter-uncertainty
#| echo: true
#| fig-cap: "Centered parameter uncertainties for a subset of genes."
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/parameter_uncertainties.pdf.png"))
```

#### Shared time

@fig-shared-time-uncertainty shows the distribution of coefficients of variation together with the mean and standard deviation (uncertainty) of the shared time for each cell. A kernel density estimate in the shared time uncertainty plot highlights the 90th percentile of the shared time standard deviation.

```{python}
#| label: fig-shared-time-uncertainty
#| echo: true
#| fig-cap: "Distribution of shared time coefficients of variation together with standard deviation (uncertainty) and mean per cell."
 
display(Image(filename=f"{dataset_summary.data_model_reports.path}/shared_time.pdf.png"))
```


## Experimentation

After having reviewed results that are currently computed systematically, we can also load the data and experiment.

Here we will load the data and posterior samples, perform the analysis used to generate the volcano plot for gene selection, and then regenerate the plot of phase portraits, temporal evolution, and shared time correlation. It would be straightforward, and perhaps preferable in some cases, to extract all the relevant parameters from the configuration dataclass object we referenced in each section above, but we will intentionally hard-code values to be concrete. Of course, feel free to generalize these as might suit your use case.

To load the posterior samples and postprocessed data

```{python}
#| label: load-posterior-samples
import pyrovelocity as pv
import scanpy as sc

logger = pv.logging.configure_logging("pyrovelocity.user_notebook")

posterior_samples = pv.io.CompressedPickle.load("models/pancreas_model2/pyrovelocity.pkl.zst")
adata = sc.read("models/pancreas_model2/postprocessed.h5ad")
```

to generate the marker genes

```{python}
#| label: generate-marker-genes
volcano_data = posterior_samples["gene_ranking"] 
putative_marker_genes = pv.analyze.pareto_frontier_genes(volcano_data=volcano_data, num_genes=6)
```

In @fig-manually-generated-rainbowplot we show the manually generated marker gene phase portraits, temporal evolution, and shared time correlation.

```{python}
#| label: fig-manually-generated-rainbowplot
#| echo: true
#| fig-cap: "Manually generated rainbow plot." 
with SuppressOutput():
  pv.plots.rainbowplot(
      volcano_data=volcano_data,
      adata=adata,
      posterior_samples=posterior_samples,
      genes=putative_marker_genes,
      data=["st", "ut"],
      basis="umap",
      cell_state="clusters",
  )
```

The best place to review the approach to generating the above plots is in [the source code for the `pyrovelocity.summarize` module](https://github.com/pinellolab/pyrovelocity/tree/beta/src/pyrovelocity/summarize.py) or in the [docs](https://github.io/pinellolab/pyrovelocity). Additional links are shown in the help below.

```{python}
#| label: print-pyrovelocity-docstring-2
pv.help.internal_help(pv)
```